{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5HpXNVnXpxrp"
      },
      "source": [
        "# Machine Learning Model using Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "J6ujo_uwexPG"
      },
      "outputs": [],
      "source": [
        "#Call Library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AEdvlzvFO4pE",
        "outputId": "aa0c4909-e9f1-46ee-d54c-756e336e2235"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RMS1</th>\n",
              "      <th>SSI1</th>\n",
              "      <th>MAV1</th>\n",
              "      <th>IEMG1</th>\n",
              "      <th>PKF1</th>\n",
              "      <th>MNP1</th>\n",
              "      <th>RMS2</th>\n",
              "      <th>SSI2</th>\n",
              "      <th>MAV2</th>\n",
              "      <th>IEMG2</th>\n",
              "      <th>...</th>\n",
              "      <th>SSI3</th>\n",
              "      <th>MAV3</th>\n",
              "      <th>IEMG3</th>\n",
              "      <th>PKF3</th>\n",
              "      <th>MNP3</th>\n",
              "      <th>BMI</th>\n",
              "      <th>BF</th>\n",
              "      <th>FFM</th>\n",
              "      <th>OR</th>\n",
              "      <th>DOMS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.140183</td>\n",
              "      <td>66.126996</td>\n",
              "      <td>0.094038</td>\n",
              "      <td>316.4380172</td>\n",
              "      <td>98.632812</td>\n",
              "      <td>764.113883</td>\n",
              "      <td>0.230391</td>\n",
              "      <td>178.454251</td>\n",
              "      <td>0.166771</td>\n",
              "      <td>560.685657</td>\n",
              "      <td>...</td>\n",
              "      <td>252.319595</td>\n",
              "      <td>0.213255</td>\n",
              "      <td>660.665117</td>\n",
              "      <td>47.851562</td>\n",
              "      <td>1439.894484</td>\n",
              "      <td>26.45</td>\n",
              "      <td>20.37</td>\n",
              "      <td>64.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.165638</td>\n",
              "      <td>110.238253</td>\n",
              "      <td>0.109068</td>\n",
              "      <td>438.2360214</td>\n",
              "      <td>113.769531</td>\n",
              "      <td>815.390316</td>\n",
              "      <td>0.209526</td>\n",
              "      <td>150.273895</td>\n",
              "      <td>0.158326</td>\n",
              "      <td>541.948709</td>\n",
              "      <td>...</td>\n",
              "      <td>107.358808</td>\n",
              "      <td>0.117995</td>\n",
              "      <td>478.234526</td>\n",
              "      <td>78.613281</td>\n",
              "      <td>724.714243</td>\n",
              "      <td>26.45</td>\n",
              "      <td>20.37</td>\n",
              "      <td>64.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.169898</td>\n",
              "      <td>103.193039</td>\n",
              "      <td>0.109656</td>\n",
              "      <td>392.0207778</td>\n",
              "      <td>19.042969</td>\n",
              "      <td>793.503828</td>\n",
              "      <td>0.261797</td>\n",
              "      <td>261.265206</td>\n",
              "      <td>0.188779</td>\n",
              "      <td>719.625686</td>\n",
              "      <td>...</td>\n",
              "      <td>467.641006</td>\n",
              "      <td>0.276446</td>\n",
              "      <td>934.111800</td>\n",
              "      <td>79.589844</td>\n",
              "      <td>1412.205261</td>\n",
              "      <td>26.45</td>\n",
              "      <td>20.37</td>\n",
              "      <td>64.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.141682</td>\n",
              "      <td>86.397151</td>\n",
              "      <td>0.093013</td>\n",
              "      <td>400.3272018</td>\n",
              "      <td>126.220703</td>\n",
              "      <td>1817.091765</td>\n",
              "      <td>0.232483</td>\n",
              "      <td>222.571131</td>\n",
              "      <td>0.173143</td>\n",
              "      <td>713.001302</td>\n",
              "      <td>...</td>\n",
              "      <td>591.568116</td>\n",
              "      <td>0.299868</td>\n",
              "      <td>1114.310622</td>\n",
              "      <td>77.148438</td>\n",
              "      <td>1194.683656</td>\n",
              "      <td>26.45</td>\n",
              "      <td>20.37</td>\n",
              "      <td>64.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.164843</td>\n",
              "      <td>91.600519</td>\n",
              "      <td>0.107669</td>\n",
              "      <td>362.9522726</td>\n",
              "      <td>140.136719</td>\n",
              "      <td>936.011274</td>\n",
              "      <td>0.177793</td>\n",
              "      <td>97.897332</td>\n",
              "      <td>0.130260</td>\n",
              "      <td>403.416318</td>\n",
              "      <td>...</td>\n",
              "      <td>105.382138</td>\n",
              "      <td>0.110829</td>\n",
              "      <td>472.351795</td>\n",
              "      <td>140.136719</td>\n",
              "      <td>2157.931252</td>\n",
              "      <td>26.45</td>\n",
              "      <td>20.37</td>\n",
              "      <td>64.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.220443</td>\n",
              "      <td>200.066393</td>\n",
              "      <td>0.159435</td>\n",
              "      <td>656.3934984</td>\n",
              "      <td>71.533203</td>\n",
              "      <td>2126.994761</td>\n",
              "      <td>0.364039</td>\n",
              "      <td>498.821935</td>\n",
              "      <td>0.276145</td>\n",
              "      <td>1039.409232</td>\n",
              "      <td>...</td>\n",
              "      <td>371.058706</td>\n",
              "      <td>0.241056</td>\n",
              "      <td>908.057718</td>\n",
              "      <td>22.460938</td>\n",
              "      <td>847.072742</td>\n",
              "      <td>17.99</td>\n",
              "      <td>9.99</td>\n",
              "      <td>46.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0.188068</td>\n",
              "      <td>179.040256</td>\n",
              "      <td>0.132626</td>\n",
              "      <td>671.3512455</td>\n",
              "      <td>42.724609</td>\n",
              "      <td>1497.221645</td>\n",
              "      <td>0.261008</td>\n",
              "      <td>317.873308</td>\n",
              "      <td>0.189106</td>\n",
              "      <td>882.368171</td>\n",
              "      <td>...</td>\n",
              "      <td>277.678856</td>\n",
              "      <td>0.173695</td>\n",
              "      <td>797.086146</td>\n",
              "      <td>54.199219</td>\n",
              "      <td>2109.974362</td>\n",
              "      <td>17.99</td>\n",
              "      <td>9.99</td>\n",
              "      <td>46.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0.206763</td>\n",
              "      <td>173.312210</td>\n",
              "      <td>0.145733</td>\n",
              "      <td>590.8014312</td>\n",
              "      <td>61.035156</td>\n",
              "      <td>605.987037</td>\n",
              "      <td>0.279763</td>\n",
              "      <td>284.736404</td>\n",
              "      <td>0.203516</td>\n",
              "      <td>740.389766</td>\n",
              "      <td>...</td>\n",
              "      <td>271.844755</td>\n",
              "      <td>0.196269</td>\n",
              "      <td>735.615732</td>\n",
              "      <td>22.949219</td>\n",
              "      <td>847.639157</td>\n",
              "      <td>17.99</td>\n",
              "      <td>9.99</td>\n",
              "      <td>46.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.229474</td>\n",
              "      <td>229.115567</td>\n",
              "      <td>0.161376</td>\n",
              "      <td>702.1464208</td>\n",
              "      <td>80.322266</td>\n",
              "      <td>2037.676449</td>\n",
              "      <td>0.302918</td>\n",
              "      <td>353.364673</td>\n",
              "      <td>0.228296</td>\n",
              "      <td>879.166753</td>\n",
              "      <td>...</td>\n",
              "      <td>278.008749</td>\n",
              "      <td>0.199205</td>\n",
              "      <td>776.303044</td>\n",
              "      <td>80.566406</td>\n",
              "      <td>773.630889</td>\n",
              "      <td>17.99</td>\n",
              "      <td>9.99</td>\n",
              "      <td>46.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0.197641</td>\n",
              "      <td>164.959375</td>\n",
              "      <td>0.134833</td>\n",
              "      <td>569.4019414</td>\n",
              "      <td>26.367188</td>\n",
              "      <td>1739.725879</td>\n",
              "      <td>0.261182</td>\n",
              "      <td>265.155610</td>\n",
              "      <td>0.194873</td>\n",
              "      <td>757.469814</td>\n",
              "      <td>...</td>\n",
              "      <td>220.179928</td>\n",
              "      <td>0.166993</td>\n",
              "      <td>653.609471</td>\n",
              "      <td>73.242188</td>\n",
              "      <td>656.069815</td>\n",
              "      <td>17.99</td>\n",
              "      <td>9.99</td>\n",
              "      <td>46.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         RMS1        SSI1      MAV1        IEMG1        PKF1         MNP1  \\\n",
              "0    0.140183   66.126996  0.094038  316.4380172   98.632812   764.113883   \n",
              "1    0.165638  110.238253  0.109068  438.2360214  113.769531   815.390316   \n",
              "2    0.169898  103.193039  0.109656  392.0207778   19.042969   793.503828   \n",
              "3    0.141682   86.397151  0.093013  400.3272018  126.220703  1817.091765   \n",
              "4    0.164843   91.600519  0.107669  362.9522726  140.136719   936.011274   \n",
              "..        ...         ...       ...          ...         ...          ...   \n",
              "99   0.220443  200.066393  0.159435  656.3934984   71.533203  2126.994761   \n",
              "100  0.188068  179.040256  0.132626  671.3512455   42.724609  1497.221645   \n",
              "101  0.206763  173.312210  0.145733  590.8014312   61.035156   605.987037   \n",
              "102  0.229474  229.115567  0.161376  702.1464208   80.322266  2037.676449   \n",
              "103  0.197641  164.959375  0.134833  569.4019414   26.367188  1739.725879   \n",
              "\n",
              "         RMS2        SSI2      MAV2        IEMG2  ...        SSI3      MAV3  \\\n",
              "0    0.230391  178.454251  0.166771   560.685657  ...  252.319595  0.213255   \n",
              "1    0.209526  150.273895  0.158326   541.948709  ...  107.358808  0.117995   \n",
              "2    0.261797  261.265206  0.188779   719.625686  ...  467.641006  0.276446   \n",
              "3    0.232483  222.571131  0.173143   713.001302  ...  591.568116  0.299868   \n",
              "4    0.177793   97.897332  0.130260   403.416318  ...  105.382138  0.110829   \n",
              "..        ...         ...       ...          ...  ...         ...       ...   \n",
              "99   0.364039  498.821935  0.276145  1039.409232  ...  371.058706  0.241056   \n",
              "100  0.261008  317.873308  0.189106   882.368171  ...  277.678856  0.173695   \n",
              "101  0.279763  284.736404  0.203516   740.389766  ...  271.844755  0.196269   \n",
              "102  0.302918  353.364673  0.228296   879.166753  ...  278.008749  0.199205   \n",
              "103  0.261182  265.155610  0.194873   757.469814  ...  220.179928  0.166993   \n",
              "\n",
              "           IEMG3        PKF3         MNP3    BMI     BF   FFM  OR  DOMS  \n",
              "0     660.665117   47.851562  1439.894484  26.45  20.37  64.5   1     1  \n",
              "1     478.234526   78.613281   724.714243  26.45  20.37  64.5   1     1  \n",
              "2     934.111800   79.589844  1412.205261  26.45  20.37  64.5   1     1  \n",
              "3    1114.310622   77.148438  1194.683656  26.45  20.37  64.5   1     1  \n",
              "4     472.351795  140.136719  2157.931252  26.45  20.37  64.5   1     0  \n",
              "..           ...         ...          ...    ...    ...   ...  ..   ...  \n",
              "99    908.057718   22.460938   847.072742  17.99   9.99  46.8   0     1  \n",
              "100   797.086146   54.199219  2109.974362  17.99   9.99  46.8   0     0  \n",
              "101   735.615732   22.949219   847.639157  17.99   9.99  46.8   0     0  \n",
              "102   776.303044   80.566406   773.630889  17.99   9.99  46.8   0     0  \n",
              "103   653.609471   73.242188   656.069815  17.99   9.99  46.8   0     0  \n",
              "\n",
              "[104 rows x 23 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Call Dataset\n",
        "data = pd.read_csv(\"Data_training.csv\", delimiter=',')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RMS1     0\n",
              "RMS3     0\n",
              "OR       0\n",
              "FFM      0\n",
              "BF       0\n",
              "BMI      0\n",
              "MNP3     0\n",
              "PKF3     0\n",
              "IEMG3    0\n",
              "MAV3     0\n",
              "SSI3     0\n",
              "MNP2     0\n",
              "SSI1     0\n",
              "PKF2     0\n",
              "IEMG2    0\n",
              "MAV2     0\n",
              "SSI2     0\n",
              "RMS2     0\n",
              "MNP1     0\n",
              "PKF1     0\n",
              "IEMG1    0\n",
              "MAV1     0\n",
              "DOMS     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Handle missing or non-numeric values\n",
        "data = data.replace(',', '', regex=True)  # Remove commas from numeric values\n",
        "data = data.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
        "\n",
        "# Check for null value\n",
        "data.isnull().sum().sort_values(ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AS7AjtHXO8Lo",
        "outputId": "9a4b18be-952e-4d9d-84f3-ce409be116b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       RMS1      SSI1      MAV1     IEMG1      PKF1      MNP1      RMS2  \\\n",
            "0 -0.966109 -0.973316 -0.939295 -1.253601  0.811202 -0.933378 -0.892981   \n",
            "1 -0.650117 -0.680738 -0.680521 -0.710220  1.451819 -0.865912 -1.123034   \n",
            "2 -0.597245 -0.727467 -0.670398 -0.916402 -2.557200 -0.894709 -0.546691   \n",
            "3 -0.947512 -0.838869 -0.956946 -0.879344  1.978778  0.452055 -0.869909   \n",
            "4 -0.659996 -0.804357 -0.704610 -1.046086  2.567732 -0.707208 -1.472928   \n",
            "\n",
            "       SSI2      MAV2     IEMG2  ...      SSI3      MAV3     IEMG3      PKF3  \\\n",
            "0 -0.926295 -0.958670 -1.221412  ...  0.035284  0.600414 -0.074135 -1.018766   \n",
            "1 -1.052644 -1.080356 -1.297526  ... -0.912097 -1.080502 -0.968508  0.095491   \n",
            "2 -0.555004 -0.641587 -0.575766  ...  1.442503  1.715451  1.266449  0.130864   \n",
            "3 -0.728492 -0.866875 -0.602675  ...  2.252421  2.128746  2.149880  0.042431   \n",
            "4 -1.287480 -1.484718 -1.860272  ... -0.925016 -1.206959 -0.997348  2.324003   \n",
            "\n",
            "       MNP3       BMI        BF       FFM  OR  DOMS  \n",
            "0  0.170050  1.214969  1.187072  1.232135   1     1  \n",
            "1 -0.743546  1.214969  1.187072  1.232135   1     1  \n",
            "2  0.134679  1.214969  1.187072  1.232135   1     1  \n",
            "3 -0.143191  1.214969  1.187072  1.232135   1     1  \n",
            "4  1.087296  1.214969  1.187072  1.232135   1     0  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "scale_columns = ['RMS1', 'SSI1', 'MAV1', 'IEMG1', 'PKF1', 'MNP1','RMS2', 'SSI2', 'MAV2', 'IEMG2', 'PKF2', 'MNP2', 'RMS3', 'SSI3', 'MAV3', 'IEMG3', 'PKF3', 'MNP3','BMI','BF','FFM']\n",
        "standardScaler = StandardScaler()\n",
        "data[scale_columns] = standardScaler.fit_transform(data[scale_columns])\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.18009029e-01, 2.12871335e+02, 1.48594221e-01, 5.97430826e+02,\n",
              "       7.94654259e+01, 1.47351408e+03, 3.11378197e-01, 3.85050484e+02,\n",
              "       2.33309268e-01, 8.61362964e+02, 6.82443472e+01, 1.20961174e+03,\n",
              "       2.45335118e-01, 2.46920678e+02, 1.79228948e-01, 6.75786805e+02,\n",
              "       7.59770320e+01, 1.30677614e+03, 2.17800000e+01, 1.48184615e+01,\n",
              "       5.48823077e+01])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "standardScaler.mean_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([8.05556134e-02, 1.50767416e+02, 5.80820397e-02, 2.24148482e+02,\n",
              "       2.36283624e+01, 7.60035040e+02, 9.06935858e-02, 2.23035099e+02,\n",
              "       6.94063728e-02, 2.46171824e+02, 2.30767773e+01, 6.46522083e+02,\n",
              "       7.81570882e-02, 1.53012020e+02, 5.66715594e-02, 2.03975904e+02,\n",
              "       2.76073988e+01, 7.82818465e+02, 3.84372015e+00, 4.67666358e+00,\n",
              "       7.80571206e+00])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "standardScaler.scale_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection by Choosing top 10 Related Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RMS1</th>\n",
              "      <th>SSI1</th>\n",
              "      <th>MAV1</th>\n",
              "      <th>IEMG1</th>\n",
              "      <th>PKF1</th>\n",
              "      <th>MNP1</th>\n",
              "      <th>RMS2</th>\n",
              "      <th>SSI2</th>\n",
              "      <th>MAV2</th>\n",
              "      <th>IEMG2</th>\n",
              "      <th>...</th>\n",
              "      <th>SSI3</th>\n",
              "      <th>MAV3</th>\n",
              "      <th>IEMG3</th>\n",
              "      <th>PKF3</th>\n",
              "      <th>MNP3</th>\n",
              "      <th>BMI</th>\n",
              "      <th>BF</th>\n",
              "      <th>FFM</th>\n",
              "      <th>OR</th>\n",
              "      <th>DOMS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RMS1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959822</td>\n",
              "      <td>0.981546</td>\n",
              "      <td>0.851490</td>\n",
              "      <td>0.144924</td>\n",
              "      <td>0.445743</td>\n",
              "      <td>0.703571</td>\n",
              "      <td>0.710581</td>\n",
              "      <td>0.700227</td>\n",
              "      <td>0.703185</td>\n",
              "      <td>...</td>\n",
              "      <td>0.484672</td>\n",
              "      <td>0.480106</td>\n",
              "      <td>0.510231</td>\n",
              "      <td>0.227234</td>\n",
              "      <td>0.123463</td>\n",
              "      <td>0.237910</td>\n",
              "      <td>0.240754</td>\n",
              "      <td>0.309830</td>\n",
              "      <td>0.060703</td>\n",
              "      <td>-0.277069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSI1</th>\n",
              "      <td>0.959822</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.950999</td>\n",
              "      <td>0.930663</td>\n",
              "      <td>0.133491</td>\n",
              "      <td>0.481879</td>\n",
              "      <td>0.659170</td>\n",
              "      <td>0.691329</td>\n",
              "      <td>0.659591</td>\n",
              "      <td>0.691987</td>\n",
              "      <td>...</td>\n",
              "      <td>0.511040</td>\n",
              "      <td>0.500253</td>\n",
              "      <td>0.560730</td>\n",
              "      <td>0.238939</td>\n",
              "      <td>0.115199</td>\n",
              "      <td>0.258309</td>\n",
              "      <td>0.261420</td>\n",
              "      <td>0.325753</td>\n",
              "      <td>0.070883</td>\n",
              "      <td>-0.270720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAV1</th>\n",
              "      <td>0.981546</td>\n",
              "      <td>0.950999</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.870904</td>\n",
              "      <td>0.144550</td>\n",
              "      <td>0.427744</td>\n",
              "      <td>0.631809</td>\n",
              "      <td>0.641012</td>\n",
              "      <td>0.640087</td>\n",
              "      <td>0.653752</td>\n",
              "      <td>...</td>\n",
              "      <td>0.419960</td>\n",
              "      <td>0.424967</td>\n",
              "      <td>0.475945</td>\n",
              "      <td>0.192996</td>\n",
              "      <td>0.104391</td>\n",
              "      <td>0.195164</td>\n",
              "      <td>0.201025</td>\n",
              "      <td>0.264825</td>\n",
              "      <td>-0.013983</td>\n",
              "      <td>-0.274923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IEMG1</th>\n",
              "      <td>0.851490</td>\n",
              "      <td>0.930663</td>\n",
              "      <td>0.870904</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.078877</td>\n",
              "      <td>0.545040</td>\n",
              "      <td>0.513588</td>\n",
              "      <td>0.550722</td>\n",
              "      <td>0.515225</td>\n",
              "      <td>0.605784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.471676</td>\n",
              "      <td>0.459661</td>\n",
              "      <td>0.581502</td>\n",
              "      <td>0.167540</td>\n",
              "      <td>0.130029</td>\n",
              "      <td>0.080248</td>\n",
              "      <td>0.084041</td>\n",
              "      <td>0.115271</td>\n",
              "      <td>-0.076003</td>\n",
              "      <td>-0.348325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PKF1</th>\n",
              "      <td>0.144924</td>\n",
              "      <td>0.133491</td>\n",
              "      <td>0.144550</td>\n",
              "      <td>0.078877</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.105677</td>\n",
              "      <td>0.099902</td>\n",
              "      <td>0.106706</td>\n",
              "      <td>0.108125</td>\n",
              "      <td>0.085502</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138572</td>\n",
              "      <td>0.154859</td>\n",
              "      <td>0.122573</td>\n",
              "      <td>0.382029</td>\n",
              "      <td>0.044694</td>\n",
              "      <td>0.270556</td>\n",
              "      <td>0.268997</td>\n",
              "      <td>0.290737</td>\n",
              "      <td>0.164708</td>\n",
              "      <td>-0.094738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MNP1</th>\n",
              "      <td>0.445743</td>\n",
              "      <td>0.481879</td>\n",
              "      <td>0.427744</td>\n",
              "      <td>0.545040</td>\n",
              "      <td>0.105677</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.201000</td>\n",
              "      <td>0.241519</td>\n",
              "      <td>0.181350</td>\n",
              "      <td>0.307184</td>\n",
              "      <td>...</td>\n",
              "      <td>0.348270</td>\n",
              "      <td>0.299809</td>\n",
              "      <td>0.442674</td>\n",
              "      <td>0.007104</td>\n",
              "      <td>0.396854</td>\n",
              "      <td>-0.056977</td>\n",
              "      <td>-0.053599</td>\n",
              "      <td>-0.060512</td>\n",
              "      <td>-0.244128</td>\n",
              "      <td>-0.034960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMS2</th>\n",
              "      <td>0.703571</td>\n",
              "      <td>0.659170</td>\n",
              "      <td>0.631809</td>\n",
              "      <td>0.513588</td>\n",
              "      <td>0.099902</td>\n",
              "      <td>0.201000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.976069</td>\n",
              "      <td>0.994056</td>\n",
              "      <td>0.921758</td>\n",
              "      <td>...</td>\n",
              "      <td>0.489089</td>\n",
              "      <td>0.480149</td>\n",
              "      <td>0.415023</td>\n",
              "      <td>0.233349</td>\n",
              "      <td>0.003196</td>\n",
              "      <td>0.270631</td>\n",
              "      <td>0.260613</td>\n",
              "      <td>0.306957</td>\n",
              "      <td>0.266748</td>\n",
              "      <td>-0.191051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSI2</th>\n",
              "      <td>0.710581</td>\n",
              "      <td>0.691329</td>\n",
              "      <td>0.641012</td>\n",
              "      <td>0.550722</td>\n",
              "      <td>0.106706</td>\n",
              "      <td>0.241519</td>\n",
              "      <td>0.976069</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.971230</td>\n",
              "      <td>0.955643</td>\n",
              "      <td>...</td>\n",
              "      <td>0.532756</td>\n",
              "      <td>0.500982</td>\n",
              "      <td>0.484439</td>\n",
              "      <td>0.270085</td>\n",
              "      <td>0.055694</td>\n",
              "      <td>0.304453</td>\n",
              "      <td>0.295244</td>\n",
              "      <td>0.339419</td>\n",
              "      <td>0.257001</td>\n",
              "      <td>-0.159874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAV2</th>\n",
              "      <td>0.700227</td>\n",
              "      <td>0.659591</td>\n",
              "      <td>0.640087</td>\n",
              "      <td>0.515225</td>\n",
              "      <td>0.108125</td>\n",
              "      <td>0.181350</td>\n",
              "      <td>0.994056</td>\n",
              "      <td>0.971230</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.927438</td>\n",
              "      <td>...</td>\n",
              "      <td>0.428789</td>\n",
              "      <td>0.424341</td>\n",
              "      <td>0.366721</td>\n",
              "      <td>0.228321</td>\n",
              "      <td>-0.024913</td>\n",
              "      <td>0.290551</td>\n",
              "      <td>0.281300</td>\n",
              "      <td>0.320575</td>\n",
              "      <td>0.249701</td>\n",
              "      <td>-0.196807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IEMG2</th>\n",
              "      <td>0.703185</td>\n",
              "      <td>0.691987</td>\n",
              "      <td>0.653752</td>\n",
              "      <td>0.605784</td>\n",
              "      <td>0.085502</td>\n",
              "      <td>0.307184</td>\n",
              "      <td>0.921758</td>\n",
              "      <td>0.955643</td>\n",
              "      <td>0.927438</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.474322</td>\n",
              "      <td>0.432208</td>\n",
              "      <td>0.488702</td>\n",
              "      <td>0.254087</td>\n",
              "      <td>0.100243</td>\n",
              "      <td>0.241477</td>\n",
              "      <td>0.233484</td>\n",
              "      <td>0.263473</td>\n",
              "      <td>0.133683</td>\n",
              "      <td>-0.161081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PKF2</th>\n",
              "      <td>0.113957</td>\n",
              "      <td>0.177180</td>\n",
              "      <td>0.151151</td>\n",
              "      <td>0.209976</td>\n",
              "      <td>0.205718</td>\n",
              "      <td>0.145096</td>\n",
              "      <td>-0.127187</td>\n",
              "      <td>-0.072906</td>\n",
              "      <td>-0.116329</td>\n",
              "      <td>-0.060871</td>\n",
              "      <td>...</td>\n",
              "      <td>0.067268</td>\n",
              "      <td>0.073270</td>\n",
              "      <td>0.121219</td>\n",
              "      <td>0.190508</td>\n",
              "      <td>0.222822</td>\n",
              "      <td>0.203451</td>\n",
              "      <td>0.209931</td>\n",
              "      <td>0.165009</td>\n",
              "      <td>-0.011506</td>\n",
              "      <td>-0.236499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MNP2</th>\n",
              "      <td>0.302003</td>\n",
              "      <td>0.295322</td>\n",
              "      <td>0.275262</td>\n",
              "      <td>0.257934</td>\n",
              "      <td>0.188099</td>\n",
              "      <td>0.285317</td>\n",
              "      <td>0.209611</td>\n",
              "      <td>0.236774</td>\n",
              "      <td>0.191555</td>\n",
              "      <td>0.261543</td>\n",
              "      <td>...</td>\n",
              "      <td>0.344634</td>\n",
              "      <td>0.295773</td>\n",
              "      <td>0.388818</td>\n",
              "      <td>0.139241</td>\n",
              "      <td>0.608449</td>\n",
              "      <td>0.124747</td>\n",
              "      <td>0.125486</td>\n",
              "      <td>0.111238</td>\n",
              "      <td>-0.137573</td>\n",
              "      <td>-0.115370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMS3</th>\n",
              "      <td>0.498260</td>\n",
              "      <td>0.505759</td>\n",
              "      <td>0.426843</td>\n",
              "      <td>0.447956</td>\n",
              "      <td>0.152218</td>\n",
              "      <td>0.304721</td>\n",
              "      <td>0.521499</td>\n",
              "      <td>0.538925</td>\n",
              "      <td>0.460196</td>\n",
              "      <td>0.459282</td>\n",
              "      <td>...</td>\n",
              "      <td>0.980686</td>\n",
              "      <td>0.991740</td>\n",
              "      <td>0.905641</td>\n",
              "      <td>0.160096</td>\n",
              "      <td>0.159117</td>\n",
              "      <td>0.138228</td>\n",
              "      <td>0.127129</td>\n",
              "      <td>0.238163</td>\n",
              "      <td>0.243495</td>\n",
              "      <td>-0.058445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSI3</th>\n",
              "      <td>0.484672</td>\n",
              "      <td>0.511040</td>\n",
              "      <td>0.419960</td>\n",
              "      <td>0.471676</td>\n",
              "      <td>0.138572</td>\n",
              "      <td>0.348270</td>\n",
              "      <td>0.489089</td>\n",
              "      <td>0.532756</td>\n",
              "      <td>0.428789</td>\n",
              "      <td>0.474322</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.975969</td>\n",
              "      <td>0.944542</td>\n",
              "      <td>0.168106</td>\n",
              "      <td>0.201390</td>\n",
              "      <td>0.128200</td>\n",
              "      <td>0.118653</td>\n",
              "      <td>0.226917</td>\n",
              "      <td>0.230693</td>\n",
              "      <td>-0.034932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAV3</th>\n",
              "      <td>0.480106</td>\n",
              "      <td>0.500253</td>\n",
              "      <td>0.424967</td>\n",
              "      <td>0.459661</td>\n",
              "      <td>0.154859</td>\n",
              "      <td>0.299809</td>\n",
              "      <td>0.480149</td>\n",
              "      <td>0.500982</td>\n",
              "      <td>0.424341</td>\n",
              "      <td>0.432208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.975969</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.919709</td>\n",
              "      <td>0.128547</td>\n",
              "      <td>0.128640</td>\n",
              "      <td>0.142071</td>\n",
              "      <td>0.132360</td>\n",
              "      <td>0.244840</td>\n",
              "      <td>0.214651</td>\n",
              "      <td>-0.043366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IEMG3</th>\n",
              "      <td>0.510231</td>\n",
              "      <td>0.560730</td>\n",
              "      <td>0.475945</td>\n",
              "      <td>0.581502</td>\n",
              "      <td>0.122573</td>\n",
              "      <td>0.442674</td>\n",
              "      <td>0.415023</td>\n",
              "      <td>0.484439</td>\n",
              "      <td>0.366721</td>\n",
              "      <td>0.488702</td>\n",
              "      <td>...</td>\n",
              "      <td>0.944542</td>\n",
              "      <td>0.919709</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.140912</td>\n",
              "      <td>0.303736</td>\n",
              "      <td>0.137000</td>\n",
              "      <td>0.131691</td>\n",
              "      <td>0.206554</td>\n",
              "      <td>0.044565</td>\n",
              "      <td>0.000841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PKF3</th>\n",
              "      <td>0.227234</td>\n",
              "      <td>0.238939</td>\n",
              "      <td>0.192996</td>\n",
              "      <td>0.167540</td>\n",
              "      <td>0.382029</td>\n",
              "      <td>0.007104</td>\n",
              "      <td>0.233349</td>\n",
              "      <td>0.270085</td>\n",
              "      <td>0.228321</td>\n",
              "      <td>0.254087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.168106</td>\n",
              "      <td>0.128547</td>\n",
              "      <td>0.140912</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.057061</td>\n",
              "      <td>0.263865</td>\n",
              "      <td>0.258950</td>\n",
              "      <td>0.263861</td>\n",
              "      <td>0.233050</td>\n",
              "      <td>-0.179319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MNP3</th>\n",
              "      <td>0.123463</td>\n",
              "      <td>0.115199</td>\n",
              "      <td>0.104391</td>\n",
              "      <td>0.130029</td>\n",
              "      <td>0.044694</td>\n",
              "      <td>0.396854</td>\n",
              "      <td>0.003196</td>\n",
              "      <td>0.055694</td>\n",
              "      <td>-0.024913</td>\n",
              "      <td>0.100243</td>\n",
              "      <td>...</td>\n",
              "      <td>0.201390</td>\n",
              "      <td>0.128640</td>\n",
              "      <td>0.303736</td>\n",
              "      <td>0.057061</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.041002</td>\n",
              "      <td>-0.033225</td>\n",
              "      <td>-0.061972</td>\n",
              "      <td>-0.218099</td>\n",
              "      <td>0.044388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>0.237910</td>\n",
              "      <td>0.258309</td>\n",
              "      <td>0.195164</td>\n",
              "      <td>0.080248</td>\n",
              "      <td>0.270556</td>\n",
              "      <td>-0.056977</td>\n",
              "      <td>0.270631</td>\n",
              "      <td>0.304453</td>\n",
              "      <td>0.290551</td>\n",
              "      <td>0.241477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.128200</td>\n",
              "      <td>0.142071</td>\n",
              "      <td>0.137000</td>\n",
              "      <td>0.263865</td>\n",
              "      <td>-0.041002</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999312</td>\n",
              "      <td>0.966710</td>\n",
              "      <td>0.376152</td>\n",
              "      <td>0.067726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BF</th>\n",
              "      <td>0.240754</td>\n",
              "      <td>0.261420</td>\n",
              "      <td>0.201025</td>\n",
              "      <td>0.084041</td>\n",
              "      <td>0.268997</td>\n",
              "      <td>-0.053599</td>\n",
              "      <td>0.260613</td>\n",
              "      <td>0.295244</td>\n",
              "      <td>0.281300</td>\n",
              "      <td>0.233484</td>\n",
              "      <td>...</td>\n",
              "      <td>0.118653</td>\n",
              "      <td>0.132360</td>\n",
              "      <td>0.131691</td>\n",
              "      <td>0.258950</td>\n",
              "      <td>-0.033225</td>\n",
              "      <td>0.999312</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.966294</td>\n",
              "      <td>0.360603</td>\n",
              "      <td>0.078376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFM</th>\n",
              "      <td>0.309830</td>\n",
              "      <td>0.325753</td>\n",
              "      <td>0.264825</td>\n",
              "      <td>0.115271</td>\n",
              "      <td>0.290737</td>\n",
              "      <td>-0.060512</td>\n",
              "      <td>0.306957</td>\n",
              "      <td>0.339419</td>\n",
              "      <td>0.320575</td>\n",
              "      <td>0.263473</td>\n",
              "      <td>...</td>\n",
              "      <td>0.226917</td>\n",
              "      <td>0.244840</td>\n",
              "      <td>0.206554</td>\n",
              "      <td>0.263861</td>\n",
              "      <td>-0.061972</td>\n",
              "      <td>0.966710</td>\n",
              "      <td>0.966294</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.467042</td>\n",
              "      <td>0.105532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OR</th>\n",
              "      <td>0.060703</td>\n",
              "      <td>0.070883</td>\n",
              "      <td>-0.013983</td>\n",
              "      <td>-0.076003</td>\n",
              "      <td>0.164708</td>\n",
              "      <td>-0.244128</td>\n",
              "      <td>0.266748</td>\n",
              "      <td>0.257001</td>\n",
              "      <td>0.249701</td>\n",
              "      <td>0.133683</td>\n",
              "      <td>...</td>\n",
              "      <td>0.230693</td>\n",
              "      <td>0.214651</td>\n",
              "      <td>0.044565</td>\n",
              "      <td>0.233050</td>\n",
              "      <td>-0.218099</td>\n",
              "      <td>0.376152</td>\n",
              "      <td>0.360603</td>\n",
              "      <td>0.467042</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.187120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DOMS</th>\n",
              "      <td>-0.277069</td>\n",
              "      <td>-0.270720</td>\n",
              "      <td>-0.274923</td>\n",
              "      <td>-0.348325</td>\n",
              "      <td>-0.094738</td>\n",
              "      <td>-0.034960</td>\n",
              "      <td>-0.191051</td>\n",
              "      <td>-0.159874</td>\n",
              "      <td>-0.196807</td>\n",
              "      <td>-0.161081</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.034932</td>\n",
              "      <td>-0.043366</td>\n",
              "      <td>0.000841</td>\n",
              "      <td>-0.179319</td>\n",
              "      <td>0.044388</td>\n",
              "      <td>0.067726</td>\n",
              "      <td>0.078376</td>\n",
              "      <td>0.105532</td>\n",
              "      <td>-0.187120</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           RMS1      SSI1      MAV1     IEMG1      PKF1      MNP1      RMS2  \\\n",
              "RMS1   1.000000  0.959822  0.981546  0.851490  0.144924  0.445743  0.703571   \n",
              "SSI1   0.959822  1.000000  0.950999  0.930663  0.133491  0.481879  0.659170   \n",
              "MAV1   0.981546  0.950999  1.000000  0.870904  0.144550  0.427744  0.631809   \n",
              "IEMG1  0.851490  0.930663  0.870904  1.000000  0.078877  0.545040  0.513588   \n",
              "PKF1   0.144924  0.133491  0.144550  0.078877  1.000000  0.105677  0.099902   \n",
              "MNP1   0.445743  0.481879  0.427744  0.545040  0.105677  1.000000  0.201000   \n",
              "RMS2   0.703571  0.659170  0.631809  0.513588  0.099902  0.201000  1.000000   \n",
              "SSI2   0.710581  0.691329  0.641012  0.550722  0.106706  0.241519  0.976069   \n",
              "MAV2   0.700227  0.659591  0.640087  0.515225  0.108125  0.181350  0.994056   \n",
              "IEMG2  0.703185  0.691987  0.653752  0.605784  0.085502  0.307184  0.921758   \n",
              "PKF2   0.113957  0.177180  0.151151  0.209976  0.205718  0.145096 -0.127187   \n",
              "MNP2   0.302003  0.295322  0.275262  0.257934  0.188099  0.285317  0.209611   \n",
              "RMS3   0.498260  0.505759  0.426843  0.447956  0.152218  0.304721  0.521499   \n",
              "SSI3   0.484672  0.511040  0.419960  0.471676  0.138572  0.348270  0.489089   \n",
              "MAV3   0.480106  0.500253  0.424967  0.459661  0.154859  0.299809  0.480149   \n",
              "IEMG3  0.510231  0.560730  0.475945  0.581502  0.122573  0.442674  0.415023   \n",
              "PKF3   0.227234  0.238939  0.192996  0.167540  0.382029  0.007104  0.233349   \n",
              "MNP3   0.123463  0.115199  0.104391  0.130029  0.044694  0.396854  0.003196   \n",
              "BMI    0.237910  0.258309  0.195164  0.080248  0.270556 -0.056977  0.270631   \n",
              "BF     0.240754  0.261420  0.201025  0.084041  0.268997 -0.053599  0.260613   \n",
              "FFM    0.309830  0.325753  0.264825  0.115271  0.290737 -0.060512  0.306957   \n",
              "OR     0.060703  0.070883 -0.013983 -0.076003  0.164708 -0.244128  0.266748   \n",
              "DOMS  -0.277069 -0.270720 -0.274923 -0.348325 -0.094738 -0.034960 -0.191051   \n",
              "\n",
              "           SSI2      MAV2     IEMG2  ...      SSI3      MAV3     IEMG3  \\\n",
              "RMS1   0.710581  0.700227  0.703185  ...  0.484672  0.480106  0.510231   \n",
              "SSI1   0.691329  0.659591  0.691987  ...  0.511040  0.500253  0.560730   \n",
              "MAV1   0.641012  0.640087  0.653752  ...  0.419960  0.424967  0.475945   \n",
              "IEMG1  0.550722  0.515225  0.605784  ...  0.471676  0.459661  0.581502   \n",
              "PKF1   0.106706  0.108125  0.085502  ...  0.138572  0.154859  0.122573   \n",
              "MNP1   0.241519  0.181350  0.307184  ...  0.348270  0.299809  0.442674   \n",
              "RMS2   0.976069  0.994056  0.921758  ...  0.489089  0.480149  0.415023   \n",
              "SSI2   1.000000  0.971230  0.955643  ...  0.532756  0.500982  0.484439   \n",
              "MAV2   0.971230  1.000000  0.927438  ...  0.428789  0.424341  0.366721   \n",
              "IEMG2  0.955643  0.927438  1.000000  ...  0.474322  0.432208  0.488702   \n",
              "PKF2  -0.072906 -0.116329 -0.060871  ...  0.067268  0.073270  0.121219   \n",
              "MNP2   0.236774  0.191555  0.261543  ...  0.344634  0.295773  0.388818   \n",
              "RMS3   0.538925  0.460196  0.459282  ...  0.980686  0.991740  0.905641   \n",
              "SSI3   0.532756  0.428789  0.474322  ...  1.000000  0.975969  0.944542   \n",
              "MAV3   0.500982  0.424341  0.432208  ...  0.975969  1.000000  0.919709   \n",
              "IEMG3  0.484439  0.366721  0.488702  ...  0.944542  0.919709  1.000000   \n",
              "PKF3   0.270085  0.228321  0.254087  ...  0.168106  0.128547  0.140912   \n",
              "MNP3   0.055694 -0.024913  0.100243  ...  0.201390  0.128640  0.303736   \n",
              "BMI    0.304453  0.290551  0.241477  ...  0.128200  0.142071  0.137000   \n",
              "BF     0.295244  0.281300  0.233484  ...  0.118653  0.132360  0.131691   \n",
              "FFM    0.339419  0.320575  0.263473  ...  0.226917  0.244840  0.206554   \n",
              "OR     0.257001  0.249701  0.133683  ...  0.230693  0.214651  0.044565   \n",
              "DOMS  -0.159874 -0.196807 -0.161081  ... -0.034932 -0.043366  0.000841   \n",
              "\n",
              "           PKF3      MNP3       BMI        BF       FFM        OR      DOMS  \n",
              "RMS1   0.227234  0.123463  0.237910  0.240754  0.309830  0.060703 -0.277069  \n",
              "SSI1   0.238939  0.115199  0.258309  0.261420  0.325753  0.070883 -0.270720  \n",
              "MAV1   0.192996  0.104391  0.195164  0.201025  0.264825 -0.013983 -0.274923  \n",
              "IEMG1  0.167540  0.130029  0.080248  0.084041  0.115271 -0.076003 -0.348325  \n",
              "PKF1   0.382029  0.044694  0.270556  0.268997  0.290737  0.164708 -0.094738  \n",
              "MNP1   0.007104  0.396854 -0.056977 -0.053599 -0.060512 -0.244128 -0.034960  \n",
              "RMS2   0.233349  0.003196  0.270631  0.260613  0.306957  0.266748 -0.191051  \n",
              "SSI2   0.270085  0.055694  0.304453  0.295244  0.339419  0.257001 -0.159874  \n",
              "MAV2   0.228321 -0.024913  0.290551  0.281300  0.320575  0.249701 -0.196807  \n",
              "IEMG2  0.254087  0.100243  0.241477  0.233484  0.263473  0.133683 -0.161081  \n",
              "PKF2   0.190508  0.222822  0.203451  0.209931  0.165009 -0.011506 -0.236499  \n",
              "MNP2   0.139241  0.608449  0.124747  0.125486  0.111238 -0.137573 -0.115370  \n",
              "RMS3   0.160096  0.159117  0.138228  0.127129  0.238163  0.243495 -0.058445  \n",
              "SSI3   0.168106  0.201390  0.128200  0.118653  0.226917  0.230693 -0.034932  \n",
              "MAV3   0.128547  0.128640  0.142071  0.132360  0.244840  0.214651 -0.043366  \n",
              "IEMG3  0.140912  0.303736  0.137000  0.131691  0.206554  0.044565  0.000841  \n",
              "PKF3   1.000000  0.057061  0.263865  0.258950  0.263861  0.233050 -0.179319  \n",
              "MNP3   0.057061  1.000000 -0.041002 -0.033225 -0.061972 -0.218099  0.044388  \n",
              "BMI    0.263865 -0.041002  1.000000  0.999312  0.966710  0.376152  0.067726  \n",
              "BF     0.258950 -0.033225  0.999312  1.000000  0.966294  0.360603  0.078376  \n",
              "FFM    0.263861 -0.061972  0.966710  0.966294  1.000000  0.467042  0.105532  \n",
              "OR     0.233050 -0.218099  0.376152  0.360603  0.467042  1.000000 -0.187120  \n",
              "DOMS  -0.179319  0.044388  0.067726  0.078376  0.105532 -0.187120  1.000000  \n",
              "\n",
              "[23 rows x 23 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_data = data.corr()\n",
        "corr_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "IEMG1    0.348325\n",
              "RMS1     0.277069\n",
              "MAV1     0.274923\n",
              "SSI1     0.270720\n",
              "PKF2     0.236499\n",
              "MAV2     0.196807\n",
              "RMS2     0.191051\n",
              "OR       0.187120\n",
              "PKF3     0.179319\n",
              "IEMG2    0.161081\n",
              "SSI2     0.159874\n",
              "MNP2     0.115370\n",
              "FFM      0.105532\n",
              "PKF1     0.094738\n",
              "BF       0.078376\n",
              "BMI      0.067726\n",
              "RMS3     0.058445\n",
              "MNP3     0.044388\n",
              "MAV3     0.043366\n",
              "MNP1     0.034960\n",
              "SSI3     0.034932\n",
              "IEMG3    0.000841\n",
              "Name: DOMS, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "strong_relation_features = pd.Series(abs(corr_data['DOMS'])).nlargest(n=25).iloc[1:] #nlargest(n=7)==> take 6 features\n",
        "strong_relation_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RMS1</th>\n",
              "      <th>SSI1</th>\n",
              "      <th>MAV1</th>\n",
              "      <th>IEMG1</th>\n",
              "      <th>RMS2</th>\n",
              "      <th>MAV2</th>\n",
              "      <th>IEMG2</th>\n",
              "      <th>PKF2</th>\n",
              "      <th>PKF3</th>\n",
              "      <th>OR</th>\n",
              "      <th>DOMS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.966109</td>\n",
              "      <td>-0.973316</td>\n",
              "      <td>-0.939295</td>\n",
              "      <td>-1.253601</td>\n",
              "      <td>-0.892981</td>\n",
              "      <td>-0.958670</td>\n",
              "      <td>-1.221412</td>\n",
              "      <td>1.951611</td>\n",
              "      <td>-1.018766</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.650117</td>\n",
              "      <td>-0.680738</td>\n",
              "      <td>-0.680521</td>\n",
              "      <td>-0.710220</td>\n",
              "      <td>-1.123034</td>\n",
              "      <td>-1.080356</td>\n",
              "      <td>-1.297526</td>\n",
              "      <td>0.597436</td>\n",
              "      <td>0.095491</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.597245</td>\n",
              "      <td>-0.727467</td>\n",
              "      <td>-0.670398</td>\n",
              "      <td>-0.916402</td>\n",
              "      <td>-0.546691</td>\n",
              "      <td>-0.641587</td>\n",
              "      <td>-0.575766</td>\n",
              "      <td>0.428164</td>\n",
              "      <td>0.130864</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.947512</td>\n",
              "      <td>-0.838869</td>\n",
              "      <td>-0.956946</td>\n",
              "      <td>-0.879344</td>\n",
              "      <td>-0.869909</td>\n",
              "      <td>-0.866875</td>\n",
              "      <td>-0.602675</td>\n",
              "      <td>0.544539</td>\n",
              "      <td>0.042431</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.659996</td>\n",
              "      <td>-0.804357</td>\n",
              "      <td>-0.704610</td>\n",
              "      <td>-1.046086</td>\n",
              "      <td>-1.472928</td>\n",
              "      <td>-1.484718</td>\n",
              "      <td>-1.860272</td>\n",
              "      <td>1.464955</td>\n",
              "      <td>2.324003</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.030217</td>\n",
              "      <td>-0.084932</td>\n",
              "      <td>0.186644</td>\n",
              "      <td>0.263052</td>\n",
              "      <td>0.580645</td>\n",
              "      <td>0.617171</td>\n",
              "      <td>0.723260</td>\n",
              "      <td>-1.983960</td>\n",
              "      <td>-1.938469</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>-0.371685</td>\n",
              "      <td>-0.224393</td>\n",
              "      <td>-0.274930</td>\n",
              "      <td>0.329783</td>\n",
              "      <td>-0.555383</td>\n",
              "      <td>-0.636878</td>\n",
              "      <td>0.085327</td>\n",
              "      <td>-0.111390</td>\n",
              "      <td>-0.788840</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>-0.139607</td>\n",
              "      <td>-0.262385</td>\n",
              "      <td>-0.049262</td>\n",
              "      <td>-0.029576</td>\n",
              "      <td>-0.348595</td>\n",
              "      <td>-0.429264</td>\n",
              "      <td>-0.491418</td>\n",
              "      <td>-1.941642</td>\n",
              "      <td>-1.920783</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.142319</td>\n",
              "      <td>0.107744</td>\n",
              "      <td>0.220062</td>\n",
              "      <td>0.467171</td>\n",
              "      <td>-0.093286</td>\n",
              "      <td>-0.072235</td>\n",
              "      <td>0.072323</td>\n",
              "      <td>-2.005119</td>\n",
              "      <td>0.166237</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>-0.252839</td>\n",
              "      <td>-0.317787</td>\n",
              "      <td>-0.236919</td>\n",
              "      <td>-0.125046</td>\n",
              "      <td>-0.553471</td>\n",
              "      <td>-0.553792</td>\n",
              "      <td>-0.422035</td>\n",
              "      <td>-2.005119</td>\n",
              "      <td>-0.099062</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         RMS1      SSI1      MAV1     IEMG1      RMS2      MAV2     IEMG2  \\\n",
              "0   -0.966109 -0.973316 -0.939295 -1.253601 -0.892981 -0.958670 -1.221412   \n",
              "1   -0.650117 -0.680738 -0.680521 -0.710220 -1.123034 -1.080356 -1.297526   \n",
              "2   -0.597245 -0.727467 -0.670398 -0.916402 -0.546691 -0.641587 -0.575766   \n",
              "3   -0.947512 -0.838869 -0.956946 -0.879344 -0.869909 -0.866875 -0.602675   \n",
              "4   -0.659996 -0.804357 -0.704610 -1.046086 -1.472928 -1.484718 -1.860272   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "99   0.030217 -0.084932  0.186644  0.263052  0.580645  0.617171  0.723260   \n",
              "100 -0.371685 -0.224393 -0.274930  0.329783 -0.555383 -0.636878  0.085327   \n",
              "101 -0.139607 -0.262385 -0.049262 -0.029576 -0.348595 -0.429264 -0.491418   \n",
              "102  0.142319  0.107744  0.220062  0.467171 -0.093286 -0.072235  0.072323   \n",
              "103 -0.252839 -0.317787 -0.236919 -0.125046 -0.553471 -0.553792 -0.422035   \n",
              "\n",
              "         PKF2      PKF3  OR  DOMS  \n",
              "0    1.951611 -1.018766   1     1  \n",
              "1    0.597436  0.095491   1     1  \n",
              "2    0.428164  0.130864   1     1  \n",
              "3    0.544539  0.042431   1     1  \n",
              "4    1.464955  2.324003   1     0  \n",
              "..        ...       ...  ..   ...  \n",
              "99  -1.983960 -1.938469   0     1  \n",
              "100 -0.111390 -0.788840   0     0  \n",
              "101 -1.941642 -1.920783   0     0  \n",
              "102 -2.005119  0.166237   0     0  \n",
              "103 -2.005119 -0.099062   0     0  \n",
              "\n",
              "[104 rows x 11 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data.drop(['PKF1','MNP1','SSI2','MNP2','RMS3','SSI3','MAV3','IEMG3','MNP3','BMI','BF','FFM'], axis=1)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNpZTpmfPSeC"
      },
      "outputs": [],
      "source": [
        "#Split Features and Label\n",
        "Y = data['DOMS']\n",
        "X = data.drop(['DOMS'], axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsadYONIPWLh"
      },
      "outputs": [],
      "source": [
        "# #Shuffling Features and Label\n",
        "X,Y=shuffle(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PqHVsJdPdIh"
      },
      "outputs": [],
      "source": [
        "#Splitting into data training and data testing\n",
        "x_training, x_testing, y_training, y_testing = train_test_split(X, Y, test_size = 0.2, random_state =42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lDRS9BBPitY"
      },
      "outputs": [],
      "source": [
        "#ANN Setting\n",
        "def get_basic_model():\n",
        "  model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(32, activation='sigmoid',name=\"Hidden_1\"),\n",
        "  tf.keras.layers.Dense(16, activation='sigmoid',name=\"Hidden_2\"),\n",
        "  tf.keras.layers.Dense(8, activation='sigmoid',name=\"Hidden_3\"),\n",
        "  tf.keras.layers.Dense(1, activation='linear',name=\"Output\")\n",
        "  ],\n",
        "  name=\"Sequential\")\n",
        "  # model.summary()\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "#Checkpoint to save the best accuracy\n",
        "checkpoint_filepath = \"C:/Users/Nathaniel Win/Python Project/Program TA/Checkpoint/checkpoint\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykYloHKVPujp",
        "outputId": "4300c4b8-98ea-4210-bd66-6accca2910f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52/52 [==============================] - 1s 2ms/step - loss: 0.3883 - accuracy: 0.6538\n",
            "Epoch 2/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.6538\n",
            "Epoch 3/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.6538\n",
            "Epoch 4/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.6538\n",
            "Epoch 5/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.6538\n",
            "Epoch 6/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.6538\n",
            "Epoch 7/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.6538\n",
            "Epoch 8/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.6538\n",
            "Epoch 9/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.6538\n",
            "Epoch 10/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2117 - accuracy: 0.6538\n",
            "Epoch 11/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.6538\n",
            "Epoch 12/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.6635\n",
            "Epoch 13/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.6538\n",
            "Epoch 14/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.6538\n",
            "Epoch 15/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.6538\n",
            "Epoch 16/200\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.7019\n",
            "Epoch 17/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.6538\n",
            "Epoch 18/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.6827\n",
            "Epoch 19/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.7596\n",
            "Epoch 20/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7115\n",
            "Epoch 21/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.6827\n",
            "Epoch 22/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.7692\n",
            "Epoch 23/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7500\n",
            "Epoch 24/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.7500\n",
            "Epoch 25/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7981\n",
            "Epoch 26/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.7981\n",
            "Epoch 27/200\n",
            "52/52 [==============================] - 0s 919us/step - loss: 0.1726 - accuracy: 0.7788\n",
            "Epoch 28/200\n",
            "52/52 [==============================] - 0s 848us/step - loss: 0.1698 - accuracy: 0.7692\n",
            "Epoch 29/200\n",
            "52/52 [==============================] - 0s 919us/step - loss: 0.1717 - accuracy: 0.7692\n",
            "Epoch 30/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.7788\n",
            "Epoch 31/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.7981\n",
            "Epoch 32/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.8077\n",
            "Epoch 33/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.7885\n",
            "Epoch 34/200\n",
            "52/52 [==============================] - 0s 920us/step - loss: 0.1620 - accuracy: 0.7692\n",
            "Epoch 35/200\n",
            "52/52 [==============================] - 0s 927us/step - loss: 0.1602 - accuracy: 0.7885\n",
            "Epoch 36/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.7692\n",
            "Epoch 37/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.7885\n",
            "Epoch 38/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.7885\n",
            "Epoch 39/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.7788\n",
            "Epoch 40/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.7788\n",
            "Epoch 41/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.7981\n",
            "Epoch 42/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.7788\n",
            "Epoch 43/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.7885\n",
            "Epoch 44/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.7981\n",
            "Epoch 45/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.7981\n",
            "Epoch 46/200\n",
            "52/52 [==============================] - 0s 919us/step - loss: 0.1457 - accuracy: 0.8077\n",
            "Epoch 47/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.8077\n",
            "Epoch 48/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.8077\n",
            "Epoch 49/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.7981\n",
            "Epoch 50/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.8173\n",
            "Epoch 51/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.8077\n",
            "Epoch 52/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.8077\n",
            "Epoch 53/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.7981\n",
            "Epoch 54/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.7981\n",
            "Epoch 55/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.7981\n",
            "Epoch 56/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.8077\n",
            "Epoch 57/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.7788\n",
            "Epoch 58/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.8173\n",
            "Epoch 59/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.8077\n",
            "Epoch 60/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.7981\n",
            "Epoch 61/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.8173\n",
            "Epoch 62/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.8077\n",
            "Epoch 63/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.8173\n",
            "Epoch 64/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.7981\n",
            "Epoch 65/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.8173\n",
            "Epoch 66/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.8077\n",
            "Epoch 67/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.8269\n",
            "Epoch 68/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.8077\n",
            "Epoch 69/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.8173\n",
            "Epoch 70/200\n",
            "52/52 [==============================] - 0s 928us/step - loss: 0.1292 - accuracy: 0.8077\n",
            "Epoch 71/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.8269\n",
            "Epoch 72/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.8173\n",
            "Epoch 73/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.8077\n",
            "Epoch 74/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1323 - accuracy: 0.8077\n",
            "Epoch 75/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.8077\n",
            "Epoch 76/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.8077\n",
            "Epoch 77/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.8173\n",
            "Epoch 78/200\n",
            "52/52 [==============================] - 0s 927us/step - loss: 0.1241 - accuracy: 0.8269\n",
            "Epoch 79/200\n",
            "52/52 [==============================] - 0s 919us/step - loss: 0.1255 - accuracy: 0.8173\n",
            "Epoch 80/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.8077\n",
            "Epoch 81/200\n",
            "52/52 [==============================] - 0s 927us/step - loss: 0.1241 - accuracy: 0.8173\n",
            "Epoch 82/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.8077\n",
            "Epoch 83/200\n",
            "52/52 [==============================] - 0s 840us/step - loss: 0.1232 - accuracy: 0.8269\n",
            "Epoch 84/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.8173\n",
            "Epoch 85/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.8173\n",
            "Epoch 86/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.8269\n",
            "Epoch 87/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.8365\n",
            "Epoch 88/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.8269\n",
            "Epoch 89/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.8269\n",
            "Epoch 90/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.8269\n",
            "Epoch 91/200\n",
            "52/52 [==============================] - 0s 927us/step - loss: 0.1162 - accuracy: 0.8269\n",
            "Epoch 92/200\n",
            "52/52 [==============================] - 0s 920us/step - loss: 0.1166 - accuracy: 0.8173\n",
            "Epoch 93/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1215 - accuracy: 0.8269\n",
            "Epoch 94/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.8365\n",
            "Epoch 95/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.8365\n",
            "Epoch 96/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8269\n",
            "Epoch 97/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.8173\n",
            "Epoch 98/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.8269\n",
            "Epoch 99/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.8365\n",
            "Epoch 100/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.8173\n",
            "Epoch 101/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8173\n",
            "Epoch 102/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.8365\n",
            "Epoch 103/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.8269\n",
            "Epoch 104/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.8269\n",
            "Epoch 105/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.8365\n",
            "Epoch 106/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.8077\n",
            "Epoch 107/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.8269\n",
            "Epoch 108/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.8462\n",
            "Epoch 109/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.8269\n",
            "Epoch 110/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.8558\n",
            "Epoch 111/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.8654\n",
            "Epoch 112/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.8269\n",
            "Epoch 113/200\n",
            "52/52 [==============================] - 0s 927us/step - loss: 0.1024 - accuracy: 0.8462\n",
            "Epoch 114/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.8365\n",
            "Epoch 115/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1027 - accuracy: 0.8462\n",
            "Epoch 116/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.8173\n",
            "Epoch 117/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.8558\n",
            "Epoch 118/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.1038 - accuracy: 0.8462\n",
            "Epoch 119/200\n",
            "52/52 [==============================] - 0s 928us/step - loss: 0.0985 - accuracy: 0.8558\n",
            "Epoch 120/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.8558\n",
            "Epoch 121/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0977 - accuracy: 0.8462\n",
            "Epoch 122/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0989 - accuracy: 0.8654\n",
            "Epoch 123/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.8558\n",
            "Epoch 124/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.8558\n",
            "Epoch 125/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.8750\n",
            "Epoch 126/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.8558\n",
            "Epoch 127/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.8750\n",
            "Epoch 128/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.8654\n",
            "Epoch 129/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9038\n",
            "Epoch 130/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.8846\n",
            "Epoch 131/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.8654\n",
            "Epoch 132/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.8846\n",
            "Epoch 133/200\n",
            "52/52 [==============================] - 0s 919us/step - loss: 0.0928 - accuracy: 0.8942\n",
            "Epoch 134/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9135\n",
            "Epoch 135/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.8750\n",
            "Epoch 136/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.8942\n",
            "Epoch 137/200\n",
            "52/52 [==============================] - 0s 920us/step - loss: 0.0873 - accuracy: 0.9038\n",
            "Epoch 138/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9038\n",
            "Epoch 139/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.8846\n",
            "Epoch 140/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9135\n",
            "Epoch 141/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.8942\n",
            "Epoch 142/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9038\n",
            "Epoch 143/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9038\n",
            "Epoch 144/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.8558\n",
            "Epoch 145/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.8942\n",
            "Epoch 146/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.8846\n",
            "Epoch 147/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9038\n",
            "Epoch 148/200\n",
            "52/52 [==============================] - 0s 928us/step - loss: 0.0824 - accuracy: 0.9038\n",
            "Epoch 149/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9038\n",
            "Epoch 150/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9038\n",
            "Epoch 151/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9038\n",
            "Epoch 152/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9135\n",
            "Epoch 153/200\n",
            "52/52 [==============================] - 0s 927us/step - loss: 0.0815 - accuracy: 0.9038\n",
            "Epoch 154/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9038\n",
            "Epoch 155/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.8942\n",
            "Epoch 156/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9231\n",
            "Epoch 157/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9135\n",
            "Epoch 158/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9038\n",
            "Epoch 159/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9135\n",
            "Epoch 160/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9327\n",
            "Epoch 161/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9135\n",
            "Epoch 162/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9327\n",
            "Epoch 163/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9327\n",
            "Epoch 164/200\n",
            "52/52 [==============================] - 0s 919us/step - loss: 0.0773 - accuracy: 0.9135\n",
            "Epoch 165/200\n",
            "52/52 [==============================] - 0s 929us/step - loss: 0.0772 - accuracy: 0.9231\n",
            "Epoch 166/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9135\n",
            "Epoch 167/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9135\n",
            "Epoch 168/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9423\n",
            "Epoch 169/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9231\n",
            "Epoch 170/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9327\n",
            "Epoch 171/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9327\n",
            "Epoch 172/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9135\n",
            "Epoch 173/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9423\n",
            "Epoch 174/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9231\n",
            "Epoch 175/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9327\n",
            "Epoch 176/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9135\n",
            "Epoch 177/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9519\n",
            "Epoch 178/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9423\n",
            "Epoch 179/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9327\n",
            "Epoch 180/200\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9423\n",
            "Epoch 181/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9423\n",
            "Epoch 182/200\n",
            "52/52 [==============================] - 0s 974us/step - loss: 0.0683 - accuracy: 0.9423\n",
            "Epoch 183/200\n",
            "52/52 [==============================] - 0s 980us/step - loss: 0.0686 - accuracy: 0.9327\n",
            "Epoch 184/200\n",
            "52/52 [==============================] - 0s 976us/step - loss: 0.0687 - accuracy: 0.9327\n",
            "Epoch 185/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9231\n",
            "Epoch 186/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9423\n",
            "Epoch 187/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9519\n",
            "Epoch 188/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9423\n",
            "Epoch 189/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9423\n",
            "Epoch 190/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9327\n",
            "Epoch 191/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9423\n",
            "Epoch 192/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9327\n",
            "Epoch 193/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9327\n",
            "Epoch 194/200\n",
            "52/52 [==============================] - 0s 859us/step - loss: 0.0681 - accuracy: 0.9423\n",
            "Epoch 195/200\n",
            "52/52 [==============================] - 0s 927us/step - loss: 0.0660 - accuracy: 0.9519\n",
            "Epoch 196/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9519\n",
            "Epoch 197/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9327\n",
            "Epoch 198/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9423\n",
            "Epoch 199/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9423\n",
            "Epoch 200/200\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9519\n",
            "Model: \"Sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden_1 (Dense)            (2, 32)                   352       \n",
            "                                                                 \n",
            " Hidden_2 (Dense)            (2, 16)                   528       \n",
            "                                                                 \n",
            " Hidden_3 (Dense)            (2, 8)                    136       \n",
            "                                                                 \n",
            " Output (Dense)              (2, 1)                    9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,025\n",
            "Trainable params: 1,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Training Model\n",
        "model = get_basic_model()\n",
        "model.fit(X,Y, epochs=200, batch_size=2,callbacks=model_checkpoint_callback)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DerppakuP12u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'Hidden_1/kernel:0' shape=(10, 32) dtype=float32, numpy=\n",
            "array([[-0.2285973 , -0.97627443, -0.08891128, -0.17807364, -0.12901257,\n",
            "        -0.2690783 , -0.01932449,  0.05815076,  0.17026308,  0.2821976 ,\n",
            "         0.18446629,  0.08340639, -0.30858037,  0.44668794,  0.07739967,\n",
            "         0.23778972,  0.43745106,  0.12934513,  0.22616577, -0.4723527 ,\n",
            "        -0.47752473,  0.316116  , -0.27305385,  0.12640055, -0.45543265,\n",
            "        -0.81477755,  0.16567124, -0.19201829,  0.16392417, -1.2638537 ,\n",
            "        -0.10067295, -0.24187948],\n",
            "       [ 0.55462486, -0.4791938 , -0.20092316, -0.27753964, -0.49277705,\n",
            "        -0.39732373,  0.68995506,  0.312638  , -0.00525329, -0.06928213,\n",
            "        -0.48021927, -0.30327755, -0.3769691 ,  0.6740001 ,  0.019229  ,\n",
            "         0.5368286 ,  0.12702236, -0.5952144 , -0.24332395, -0.68378896,\n",
            "        -0.6810875 , -0.09840272, -0.68652606,  0.5579943 ,  0.32499123,\n",
            "        -0.7613076 ,  0.1466802 , -0.6085029 ,  0.5135661 , -0.9687356 ,\n",
            "         0.13859506, -0.2774473 ],\n",
            "       [-0.36216167, -0.8094984 , -0.03851146, -0.26637596, -0.02690678,\n",
            "        -0.2618719 ,  0.35731223, -0.14164266, -0.2871395 , -0.21946763,\n",
            "        -0.31292263, -0.3309482 , -0.30073014,  0.7002643 , -0.06741969,\n",
            "        -0.4597467 , -0.15534817, -0.47068062, -0.07666145, -0.21849899,\n",
            "        -0.79746985, -0.5464125 ,  0.28282526, -0.1308547 ,  0.2319395 ,\n",
            "        -0.84533525, -0.7954408 , -0.00660565,  0.61720264, -1.2435923 ,\n",
            "         0.19264527, -0.6160224 ],\n",
            "       [ 0.22047625,  0.2800297 ,  0.7232176 , -0.21108425, -0.07436464,\n",
            "        -0.05053579,  0.63237613, -0.8111148 , -0.36144358, -0.03388417,\n",
            "        -1.3056769 , -0.8352961 , -0.5306683 ,  1.4904802 , -0.3561437 ,\n",
            "         0.02545247, -0.5360232 , -1.303334  , -0.50394267, -0.32588983,\n",
            "        -1.1539103 , -0.9535743 , -0.1892574 , -0.16651504,  0.3166831 ,\n",
            "         0.18158454,  0.16001037, -0.68420047,  1.494675  , -0.4609426 ,\n",
            "        -0.30888504, -0.76386964],\n",
            "       [ 0.2846418 , -1.3867499 , -1.7952583 , -0.5720714 ,  0.50514734,\n",
            "         0.24589947, -0.85733926,  1.5310086 , -0.15666302, -0.8107075 ,\n",
            "        -0.3265966 , -0.22525488, -0.32894936, -0.20094761, -0.24546324,\n",
            "        -0.22918788,  0.37990102, -0.24796383, -0.28856242,  0.88653386,\n",
            "        -0.09326278,  0.01541071, -0.2877536 , -0.4545502 ,  0.14086482,\n",
            "        -0.22873844, -0.33073285, -0.3190975 ,  0.3847607 , -0.76348984,\n",
            "        -0.35042474, -0.0323948 ],\n",
            "       [ 0.19716395, -0.8524033 , -1.2918118 , -0.64243126,  0.86949867,\n",
            "         0.8678303 , -1.1628697 ,  1.0569648 , -0.5466521 , -0.68425304,\n",
            "        -0.42184108, -0.34223795, -0.2290012 ,  0.27940878, -1.0096924 ,\n",
            "        -0.7285551 ,  0.3141625 , -0.16141836, -0.82980144,  0.8210594 ,\n",
            "        -0.21986684, -0.62356657,  0.13656287, -0.35587585,  0.723606  ,\n",
            "        -0.5776093 , -0.48794392, -0.3579497 ,  0.31260282, -0.8595846 ,\n",
            "         0.3831503 , -0.22514482],\n",
            "       [ 0.6693064 , -0.9538178 , -1.0160183 ,  0.4121527 , -0.02070097,\n",
            "        -0.29846466,  0.07906973,  1.1636908 ,  0.2877334 , -0.1394629 ,\n",
            "        -0.10575275,  0.13502155,  0.4268594 , -0.07789066,  0.04550759,\n",
            "         0.60495603,  0.05862027,  0.10318344, -0.27239215,  0.15638696,\n",
            "        -0.22999215,  0.32308623,  0.11065141,  0.27249682, -0.3489485 ,\n",
            "        -0.6706561 ,  0.22521791,  0.1673442 ,  0.14689547, -0.5520788 ,\n",
            "        -0.43209878,  0.15806584],\n",
            "       [-1.0098556 ,  0.37336954,  1.0945514 , -0.38729987, -0.2877462 ,\n",
            "        -0.54854065,  0.66569364, -0.86933357, -0.7494084 , -1.0222341 ,\n",
            "        -0.1717648 , -0.18274751,  0.37994936, -0.49204734, -0.7127653 ,\n",
            "         0.19906951, -0.39651155,  0.21852495, -0.89692885, -0.78512454,\n",
            "        -0.10596848, -0.31714   , -0.3839272 , -0.62200874,  0.83254844,\n",
            "         0.02183023, -0.1303817 , -0.13356866, -0.09716081, -0.35605234,\n",
            "        -0.0532304 ,  0.23075318],\n",
            "       [-0.07274358, -0.07508247, -0.23962097, -1.0242068 , -0.08631157,\n",
            "        -0.14586446,  0.8430629 ,  0.1846737 , -0.28851178, -1.0456576 ,\n",
            "        -0.11834538, -0.3927521 , -0.8489531 ,  0.5624392 , -0.8912581 ,\n",
            "        -0.04580751, -0.22231852, -0.30220938, -0.7822442 , -0.44117913,\n",
            "        -0.28700855, -0.7753643 ,  0.2949439 ,  0.47207648,  0.5130429 ,\n",
            "        -0.1654595 ,  0.78788626, -0.80714816, -0.11790075,  0.13559534,\n",
            "         0.2013909 , -0.16830112],\n",
            "       [ 0.4289882 , -0.0923113 , -0.61151886, -0.02997533, -0.610305  ,\n",
            "         0.02320727, -0.22587496,  1.0574198 , -0.947833  ,  0.02000234,\n",
            "        -0.45327747, -0.62033814, -0.68007016,  0.9594311 ,  0.01186598,\n",
            "        -0.16927013, -0.4025051 , -0.87454915, -0.18010113, -0.03831567,\n",
            "        -0.7321609 , -0.79914165, -0.24014577, -0.2262995 ,  0.8856533 ,\n",
            "         0.19693951,  0.8563039 , -0.09574154,  0.47308138,  1.2633007 ,\n",
            "        -0.74215555, -0.7072671 ]], dtype=float32)>, <tf.Variable 'Hidden_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
            "array([-0.43708324,  0.94829315,  1.2950369 , -0.3939444 , -0.10374515,\n",
            "       -0.01690603, -0.3248042 , -0.9337858 , -0.34437597,  0.09681015,\n",
            "       -0.6057988 , -0.52126735, -0.5140448 ,  0.5666089 , -0.04872264,\n",
            "       -0.06048252, -0.37623468, -0.544911  , -0.0949764 , -0.03522792,\n",
            "       -0.8141251 , -0.49479458, -0.05556784, -0.27266267,  0.22957405,\n",
            "        0.57152295, -0.11097222, -0.42691454,  0.6925708 ,  1.1263548 ,\n",
            "       -0.22096334, -0.316002  ], dtype=float32)>]\n",
            "[<tf.Variable 'Hidden_2/kernel:0' shape=(32, 16) dtype=float32, numpy=\n",
            "array([[ 1.00368060e-01,  5.44699766e-02,  3.34411800e-01,\n",
            "        -3.11481863e-01, -6.90265670e-02, -8.48410055e-02,\n",
            "        -7.36877248e-02,  1.95045441e-01, -4.10738498e-01,\n",
            "        -3.17176640e-01,  9.72170830e-02, -2.27389544e-01,\n",
            "        -3.60780805e-01,  4.53307897e-01, -1.05119221e-01,\n",
            "         6.61480054e-02],\n",
            "       [ 3.16230565e-01,  5.87844670e-01, -1.96663946e-01,\n",
            "        -3.53162408e-01, -3.80155116e-01,  5.21767199e-01,\n",
            "         4.61344235e-02, -3.34506065e-01,  3.80735397e-01,\n",
            "        -4.20737952e-01, -6.62320077e-01, -8.00554529e-02,\n",
            "         6.03481352e-01, -3.00934225e-01,  3.90190810e-01,\n",
            "        -5.83101809e-01],\n",
            "       [ 6.72399998e-01,  6.34152710e-01, -4.97654885e-01,\n",
            "        -5.74588180e-01, -8.64046872e-01,  1.15496866e-01,\n",
            "        -4.23956752e-01, -5.82187533e-01,  1.44665390e-01,\n",
            "        -1.64474070e-01, -4.89689022e-01, -6.09753788e-01,\n",
            "         6.33051574e-01, -2.10868910e-01,  1.18463174e-01,\n",
            "        -8.70261192e-01],\n",
            "       [-2.56094430e-02,  1.28347203e-01,  1.55132394e-02,\n",
            "         4.45279837e-01,  4.23017085e-01, -2.71310151e-01,\n",
            "        -7.98399597e-02,  1.93325371e-01,  1.05931938e-01,\n",
            "         8.95724725e-03,  3.72353911e-01, -8.06083083e-02,\n",
            "        -1.96550176e-01,  2.63322681e-01, -1.18885174e-01,\n",
            "         2.86926359e-01],\n",
            "       [ 1.05346575e-01, -6.78360686e-02, -3.44366193e-01,\n",
            "         3.61178331e-02, -5.89573264e-01,  1.89382553e-01,\n",
            "         1.02674542e-02, -4.29338753e-01,  4.74127859e-01,\n",
            "        -4.08814907e-01, -1.75938323e-01, -1.15863882e-01,\n",
            "         1.53485373e-01, -2.59642690e-01,  1.72673479e-01,\n",
            "        -5.82211137e-01],\n",
            "       [ 1.87884152e-01, -1.30512621e-02, -4.32891436e-02,\n",
            "         1.82372853e-01, -4.02328163e-01,  1.57965153e-01,\n",
            "         1.21528516e-02, -5.49513340e-01,  4.51849312e-01,\n",
            "        -4.27126765e-01, -2.93621272e-01, -5.79478443e-01,\n",
            "         6.13887534e-02, -4.31094408e-01,  3.84255588e-01,\n",
            "        -4.61567312e-01],\n",
            "       [-7.10180342e-01, -1.19035229e-01,  4.52163547e-01,\n",
            "        -1.69757400e-02,  5.42859316e-01, -1.05361342e-01,\n",
            "         3.07580233e-01,  3.77964795e-01, -8.46295208e-02,\n",
            "        -1.47122487e-01,  3.48229676e-01,  4.69112039e-01,\n",
            "        -6.17027164e-01,  6.38528764e-01, -7.03509390e-01,\n",
            "         5.99139214e-01],\n",
            "       [-5.41907907e-01, -1.25942230e-01,  5.44663787e-01,\n",
            "         2.70231366e-01,  8.63090634e-01, -7.46854961e-01,\n",
            "         3.48816812e-01,  3.60953987e-01, -3.99031579e-01,\n",
            "         5.04525065e-01,  5.65612257e-01,  6.27031624e-01,\n",
            "        -7.34468341e-01,  1.58222049e-01, -3.95732999e-01,\n",
            "         5.53298116e-01],\n",
            "       [-1.76669940e-01, -3.72108668e-01,  1.62519768e-01,\n",
            "        -2.86783110e-02,  1.61928326e-01, -4.38943923e-01,\n",
            "        -6.41666949e-02, -9.40621179e-03, -1.78671345e-01,\n",
            "         1.72359303e-01, -6.59350157e-02,  1.51084244e-01,\n",
            "        -2.79194325e-01, -6.78547844e-02, -3.40434402e-01,\n",
            "         2.99490392e-01],\n",
            "       [-3.95191699e-01,  6.80693239e-02,  2.82553047e-01,\n",
            "         4.81951922e-01,  2.68050015e-01, -1.01816401e-01,\n",
            "        -7.93393925e-02,  4.50444192e-01,  8.56941268e-02,\n",
            "         1.76428989e-01,  3.11327912e-02,  8.70722011e-02,\n",
            "        -9.72403362e-02, -9.25531015e-02, -1.11711904e-01,\n",
            "         2.49449894e-01],\n",
            "       [ 1.99706376e-01,  8.16023052e-02,  3.36427718e-01,\n",
            "        -1.78528845e-01, -1.99254438e-01,  6.40707090e-02,\n",
            "         1.64754433e-03,  2.53985167e-01, -3.94242465e-01,\n",
            "         4.50742453e-01,  2.76056796e-01,  2.31178980e-02,\n",
            "         2.30261311e-01,  1.70026720e-01, -2.79542208e-01,\n",
            "         1.20118387e-01],\n",
            "       [-1.82231233e-01, -1.73528284e-01,  1.64089441e-01,\n",
            "        -9.56868827e-02,  2.74074495e-01, -2.24762946e-01,\n",
            "        -9.64047015e-02,  3.74636650e-01, -1.73955768e-01,\n",
            "        -1.12374518e-02,  4.30389643e-01,  3.97487700e-01,\n",
            "        -2.80531079e-01,  1.38121620e-01,  7.53403679e-02,\n",
            "         1.12598352e-01],\n",
            "       [-1.72461241e-01,  1.86215997e-01, -1.24058582e-01,\n",
            "         1.74414590e-01, -2.25937247e-01,  9.17230695e-02,\n",
            "         2.58227855e-01,  3.40418428e-01, -3.23324263e-01,\n",
            "         5.49255079e-03,  3.53669643e-01,  4.18334186e-01,\n",
            "         3.59106809e-02,  3.40261400e-01, -2.09639311e-01,\n",
            "         3.80131602e-01],\n",
            "       [ 4.83144045e-01,  3.57741982e-01, -6.63635582e-02,\n",
            "        -6.88782871e-01, -1.03068061e-01,  4.54740435e-01,\n",
            "        -3.99394333e-01, -4.07896399e-01,  3.19041699e-01,\n",
            "        -9.51761603e-01, -6.41768754e-01, -3.98746520e-01,\n",
            "         3.03593010e-01, -6.59843445e-01, -5.75921573e-02,\n",
            "        -4.13734585e-01],\n",
            "       [-4.18348491e-01, -5.61344773e-02,  1.73614994e-01,\n",
            "         3.74213994e-01, -5.26843593e-02, -3.37901860e-01,\n",
            "         1.17991693e-01,  9.51102152e-02, -2.07025468e-01,\n",
            "         2.89071500e-01, -2.21775189e-01,  4.12183970e-01,\n",
            "        -2.35661492e-01, -2.18224049e-01, -3.57855469e-01,\n",
            "         3.44385266e-01],\n",
            "       [ 1.63945220e-02, -3.76239061e-01, -2.42642194e-01,\n",
            "         4.51991498e-01,  2.86454678e-01, -3.33123058e-01,\n",
            "         4.41326410e-01,  4.72174346e-01, -6.01813458e-02,\n",
            "         2.58037932e-02,  9.33244899e-02,  4.71337050e-01,\n",
            "        -7.53319561e-02,  3.14032316e-01, -4.17880535e-01,\n",
            "         2.19487920e-01],\n",
            "       [ 6.09046593e-02, -7.96255395e-02, -5.32211699e-02,\n",
            "        -1.51567146e-01, -1.00107253e-01,  9.28035602e-02,\n",
            "        -1.18496478e-01, -3.53032798e-01, -2.13385180e-01,\n",
            "         2.10997477e-01, -2.43262902e-01, -4.07756418e-02,\n",
            "         4.83799167e-02, -8.28172565e-02,  1.72810361e-01,\n",
            "        -1.21549889e-02],\n",
            "       [-2.05016002e-01, -4.33580130e-02, -8.16306770e-02,\n",
            "        -9.79532227e-02,  1.65748984e-01, -3.26147437e-01,\n",
            "         8.92307013e-02,  2.54581541e-01, -2.54233003e-01,\n",
            "         3.25169146e-01,  7.98321888e-02,  4.57521640e-02,\n",
            "        -4.17587042e-01,  2.85011917e-01, -3.49901289e-01,\n",
            "         3.82649124e-01],\n",
            "       [ 5.29663190e-02, -3.21499705e-01, -1.67817563e-01,\n",
            "        -7.76477307e-02,  9.04952660e-02, -4.30588633e-01,\n",
            "         7.22126812e-02, -1.89914722e-02, -2.93215305e-01,\n",
            "         3.42024624e-01,  4.59246486e-01,  1.31081969e-01,\n",
            "        -3.53732973e-01, -1.37156874e-01, -3.57244581e-01,\n",
            "         3.92385870e-01],\n",
            "       [ 4.42315876e-01,  3.76144767e-01, -3.11927855e-01,\n",
            "        -1.13892760e-02, -4.58924100e-02,  1.40038341e-01,\n",
            "        -1.80505097e-01, -2.90923506e-01,  5.08639872e-01,\n",
            "        -3.87315929e-01, -4.77861881e-01, -1.47797480e-01,\n",
            "         4.82114226e-01, -5.84305525e-01,  2.06676319e-01,\n",
            "        -3.88205320e-01],\n",
            "       [-1.42948613e-01, -3.22561264e-01,  4.61007595e-01,\n",
            "         1.00704215e-01,  5.19915186e-02, -2.05066204e-01,\n",
            "        -1.26999974e-01,  1.08474448e-01, -1.03143588e-01,\n",
            "         2.71064699e-01,  1.04015343e-01,  3.74282710e-02,\n",
            "        -4.44933981e-01,  1.37180667e-02,  1.70949206e-01,\n",
            "         5.10277569e-01],\n",
            "       [-3.42836052e-01, -5.75029969e-01,  2.19286069e-01,\n",
            "         2.20003668e-02,  1.95564166e-01, -3.64600390e-01,\n",
            "         3.15185517e-01,  3.14250410e-01, -6.29152000e-01,\n",
            "        -3.58551182e-02,  9.50603485e-02,  2.90456116e-01,\n",
            "         1.45551711e-01,  5.43192387e-01,  6.11716416e-04,\n",
            "         5.08257806e-01],\n",
            "       [-2.49199420e-01, -1.60031676e-01, -1.35338783e-01,\n",
            "         1.86966166e-01,  2.64930516e-01,  1.75543040e-01,\n",
            "        -2.67421007e-01, -3.67100865e-01,  3.26275170e-01,\n",
            "        -1.48785561e-01,  7.54615068e-02, -4.23900574e-01,\n",
            "         4.91320640e-02,  1.13393389e-01,  3.05270404e-01,\n",
            "        -5.62545098e-02],\n",
            "       [ 1.06870778e-01, -1.33700594e-01,  2.63198733e-01,\n",
            "         3.42555181e-03,  5.43917939e-02, -1.03381626e-01,\n",
            "         2.82418966e-01,  5.60005531e-02, -6.26660436e-02,\n",
            "        -1.83831364e-01,  4.29151088e-01,  3.87061745e-01,\n",
            "        -2.19072223e-01,  4.80358452e-02,  5.98627366e-02,\n",
            "         2.15436041e-01],\n",
            "       [ 8.30208138e-02,  5.12369633e-01, -4.71038446e-02,\n",
            "        -5.46415806e-01, -2.15334147e-01,  4.42225844e-01,\n",
            "        -1.76488549e-01, -3.99626911e-01,  1.46223396e-01,\n",
            "        -5.09676456e-01, -5.80508640e-05, -4.40213621e-01,\n",
            "         5.43100655e-01,  3.49094197e-02,  1.11070246e-01,\n",
            "        -1.26694694e-01],\n",
            "       [ 3.29665244e-02,  4.19793054e-02, -3.02744489e-02,\n",
            "         2.66691390e-02, -1.36849254e-01,  4.19331461e-01,\n",
            "        -1.92263961e-01, -3.35080683e-01,  2.61001348e-01,\n",
            "        -2.15552509e-01, -3.20616782e-01, -3.59739959e-01,\n",
            "         1.09702662e-01, -1.46235898e-01,  6.63289130e-02,\n",
            "        -4.11214828e-01],\n",
            "       [ 5.01668714e-02, -3.02079678e-01, -1.64396271e-01,\n",
            "        -1.84455544e-01, -8.83661732e-02,  1.19175725e-01,\n",
            "         3.89106065e-01,  4.09915358e-01, -3.30119342e-01,\n",
            "        -2.59911180e-01,  5.54084592e-02,  3.65949214e-01,\n",
            "        -2.09135920e-01, -5.85574545e-02, -2.11188719e-01,\n",
            "         2.45734930e-01],\n",
            "       [-3.02339077e-01, -3.86878222e-01,  5.87415742e-03,\n",
            "         1.66305065e-01,  2.29111258e-02,  2.10954472e-01,\n",
            "         3.02650332e-01,  4.07852948e-01, -2.97278184e-02,\n",
            "         2.84283400e-01,  1.49701327e-01,  3.26896548e-01,\n",
            "         1.37821928e-01,  2.15578124e-01,  3.02951574e-01,\n",
            "        -2.33642042e-01],\n",
            "       [-4.16725911e-02,  3.83979857e-01, -2.71692574e-01,\n",
            "        -5.86153269e-01, -3.74561727e-01,  2.65664756e-01,\n",
            "        -2.89140373e-01, -3.36521342e-02,  3.82816195e-01,\n",
            "        -7.23081172e-01, -2.33034775e-01, -4.08082545e-01,\n",
            "         5.67756414e-01,  1.09620944e-01,  3.97269189e-01,\n",
            "        -1.89056978e-01],\n",
            "       [ 4.39912140e-01,  2.24954724e-01, -1.73175842e-01,\n",
            "        -5.24146497e-01, -4.97601777e-01,  5.28510273e-01,\n",
            "        -2.67759949e-01, -4.42276329e-01, -8.03368613e-02,\n",
            "         1.33917868e-01, -5.50821386e-02, -5.26810527e-01,\n",
            "         1.44832090e-01, -2.00535834e-01,  5.02806544e-01,\n",
            "        -6.24376774e-01],\n",
            "       [ 1.12048164e-01, -1.30081147e-01, -1.97349504e-01,\n",
            "         3.00489403e-02, -1.89062372e-01, -7.93324411e-02,\n",
            "        -1.39025614e-01, -4.18898880e-01,  4.40240264e-01,\n",
            "         1.15326263e-01, -2.21982494e-01, -1.41645923e-01,\n",
            "        -7.63355047e-02,  2.82092858e-02,  4.21602912e-02,\n",
            "        -1.05471753e-01],\n",
            "       [-1.93759859e-01,  1.17276564e-01,  1.70358628e-01,\n",
            "         3.93534005e-01,  3.02184373e-01,  9.67193116e-03,\n",
            "         1.93095848e-01,  2.46516541e-01,  8.79787281e-03,\n",
            "         8.19811970e-02,  3.23906183e-01,  1.09147288e-01,\n",
            "         2.60818731e-02,  1.67833969e-01, -1.25017464e-01,\n",
            "         1.37963384e-01]], dtype=float32)>, <tf.Variable 'Hidden_2/bias:0' shape=(16,) dtype=float32, numpy=\n",
            "array([ 0.07117348,  0.10208904, -0.16003443, -0.09386738,  0.00287915,\n",
            "        0.08995385, -0.07730682, -0.0810321 ,  0.02642249, -0.17805359,\n",
            "       -0.08552487, -0.08516646,  0.13081576, -0.07508923,  0.0559045 ,\n",
            "       -0.1345983 ], dtype=float32)>]\n",
            "[<tf.Variable 'Hidden_3/kernel:0' shape=(16, 8) dtype=float32, numpy=\n",
            "array([[ 8.12175218e-03,  3.12406540e-01,  6.36582136e-01,\n",
            "         1.81977004e-01, -2.45832667e-01, -4.53580856e-01,\n",
            "        -6.43108368e-01, -3.21268141e-01],\n",
            "       [-6.31192505e-01,  8.38098675e-02,  4.32827801e-01,\n",
            "        -1.44454967e-02, -3.23938370e-01,  2.89567381e-01,\n",
            "        -2.35779971e-01,  3.02476943e-01],\n",
            "       [ 5.16597480e-02,  3.31821799e-01, -3.05980474e-01,\n",
            "         2.55262882e-01,  2.20579267e-01, -9.77954715e-02,\n",
            "         5.73613346e-01, -5.88223822e-02],\n",
            "       [ 4.51298833e-01,  3.75907332e-01, -4.90747362e-01,\n",
            "         1.57926857e-01,  5.57009935e-01, -3.43694128e-02,\n",
            "         4.88733441e-01,  9.81542021e-02],\n",
            "       [ 3.99536639e-01,  8.55385363e-02, -3.47182602e-01,\n",
            "         8.02224129e-03,  5.23396432e-01,  2.21800115e-02,\n",
            "         7.57116914e-01, -2.35440821e-04],\n",
            "       [ 1.44230038e-01, -2.25735635e-01,  5.23147583e-01,\n",
            "         1.78904191e-01, -5.88730097e-01, -2.29935154e-01,\n",
            "        -6.01472139e-01,  2.33082935e-01],\n",
            "       [ 7.49176666e-02, -2.86921882e-03, -7.34348148e-02,\n",
            "        -5.96169651e-01,  6.31212473e-01, -2.89541572e-01,\n",
            "         1.58001840e-01,  5.25847554e-01],\n",
            "       [ 5.19357204e-01,  4.30133998e-01, -2.23163515e-02,\n",
            "        -4.47021604e-01,  3.17479163e-01, -3.37034464e-01,\n",
            "        -1.05567593e-02,  3.68010372e-01],\n",
            "       [ 7.38591477e-02, -3.88872683e-01,  1.51385784e-01,\n",
            "         4.08432409e-02, -5.62659144e-01, -1.83552742e-01,\n",
            "        -6.27636790e-01, -5.19347727e-01],\n",
            "       [ 3.54129910e-01,  6.56133950e-01, -5.63277900e-01,\n",
            "        -5.67585588e-01, -2.60791361e-01,  1.05872564e-01,\n",
            "        -2.44786330e-02,  2.18442574e-01],\n",
            "       [-2.26547003e-01,  3.93419981e-01, -5.24506092e-01,\n",
            "        -5.22333503e-01,  2.55856127e-01,  1.65567875e-01,\n",
            "         6.86938822e-01, -4.14748713e-02],\n",
            "       [ 5.60347259e-01,  3.14519972e-01, -5.23879647e-01,\n",
            "        -4.20603901e-01,  4.78703827e-01, -7.64003038e-01,\n",
            "         5.58827333e-02, -1.19109206e-01],\n",
            "       [-3.28300670e-02, -7.06420124e-01,  3.59903097e-01,\n",
            "         7.19635904e-01, -4.88051206e-01,  6.28433168e-01,\n",
            "        -8.44547212e-01, -3.36276591e-01],\n",
            "       [ 1.17925450e-01, -3.73413086e-01, -3.80024761e-01,\n",
            "         9.96284746e-03,  9.99269187e-02, -3.14813465e-01,\n",
            "         5.14013886e-01, -2.11061314e-01],\n",
            "       [-3.24377149e-01,  1.96415335e-02,  4.59134519e-01,\n",
            "         5.87288082e-01,  3.48910123e-01,  1.66172988e-03,\n",
            "        -3.89143199e-01,  3.79197210e-01],\n",
            "       [ 6.00976110e-01,  7.15601802e-01, -5.83235502e-01,\n",
            "        -8.15735221e-01,  6.23594001e-02, -2.86356002e-01,\n",
            "         8.13013256e-01,  7.67191350e-01]], dtype=float32)>, <tf.Variable 'Hidden_3/bias:0' shape=(8,) dtype=float32, numpy=\n",
            "array([ 0.0209794 , -0.00950916, -0.01826035, -0.01855106,  0.05654862,\n",
            "       -0.10523497,  0.04600529,  0.1041428 ], dtype=float32)>]\n",
            "[<tf.Variable 'Output/kernel:0' shape=(8, 1) dtype=float32, numpy=\n",
            "array([[ 0.2401085 ],\n",
            "       [ 0.27782628],\n",
            "       [-0.5388612 ],\n",
            "       [-0.69085264],\n",
            "       [ 0.5587577 ],\n",
            "       [-0.4282835 ],\n",
            "       [ 0.6144492 ],\n",
            "       [ 0.18620795]], dtype=float32)>, <tf.Variable 'Output/bias:0' shape=(1,) dtype=float32, numpy=array([0.13622299], dtype=float32)>]\n"
          ]
        }
      ],
      "source": [
        "model.load_weights(checkpoint_filepath) #To load the checkpoint\n",
        "print(model.layers[0].weights) #Print Weight and Bias in Hidden Layer 1\n",
        "print(model.layers[1].weights) #Print Weight and Bias in Hidden Layer 2\n",
        "print(model.layers[2].weights) #Print Weight and Bias in Hidden Layer 3\n",
        "print(model.layers[3].weights) #Print Weight and Bias in Output Layer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5UDz8yeMZwQ",
        "outputId": "49285349-e68e-40ac-857d-d091aa60b4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 125ms/step - loss: 0.0879 - accuracy: 0.9048\n",
            "Test accuracy: 90.47619104385376 %\n",
            "Test loss: 8.789869397878647 %\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(x_testing,  y_testing, verbose=1)\n",
        "\n",
        "print(f'Test accuracy: {test_acc * 100} %')\n",
        "print(f'Test loss: {test_loss * 100} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCyxDNsLOSOe",
        "outputId": "6233b2db-7ed1-4ec5-97d0-01e434d717fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21, 10)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_testing.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ2SNZv6QF-K",
        "outputId": "da6202bb-e8cc-415a-9594-03518606a33a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 0.20422558],\n",
              "       [-0.03453374],\n",
              "       [ 0.31187597],\n",
              "       [ 0.4830605 ],\n",
              "       [-0.18003514],\n",
              "       [ 1.3187114 ],\n",
              "       [ 0.52955365],\n",
              "       [ 0.0400628 ],\n",
              "       [-0.2819092 ],\n",
              "       [ 0.43766892],\n",
              "       [ 0.7123685 ],\n",
              "       [ 0.9549445 ],\n",
              "       [ 0.15833265],\n",
              "       [ 0.08556917],\n",
              "       [ 0.21459647],\n",
              "       [ 0.23898496],\n",
              "       [ 0.3701107 ],\n",
              "       [-0.03123231],\n",
              "       [ 0.75205004],\n",
              "       [ 0.67664456],\n",
              "       [ 0.4891229 ]], dtype=float32)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Prediction using data test\n",
        "prediction = model.predict(x_testing)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YTwis00QKpp",
        "outputId": "d05e41bf-5840-4bec-fe9c-95a9c5371dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[1.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[0.]\n",
            "[1.]\n",
            "[1.]\n",
            "[0.]\n"
          ]
        }
      ],
      "source": [
        "# Change the result of prediction into binary\n",
        "for i in range(len(prediction)):\n",
        "    if prediction[i] >= 0.5:\n",
        "      prediction[i]=1\n",
        "    else: prediction[i]=0\n",
        "    print(prediction[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "M9Ys3aiIQPpw",
        "outputId": "aaccf9f7-dc26-4951-ddf8-de1a8b05c984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        15\n",
            "           1       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.90        21\n",
            "   macro avg       0.88      0.88      0.88        21\n",
            "weighted avg       0.90      0.90      0.90        21\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Confussion Matrix\n",
        "conmat=confusion_matrix(y_testing,prediction)\n",
        "sns.heatmap(conmat.T, square=True, annot=True, fmt='d', cbar=False) \n",
        "plt.xlabel('true class') \n",
        "plt.ylabel('predicted class')\n",
        "print(classification_report(y_testing,prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       RMS1      SSI1      MAV1     IEMG1        PKF1         MNP1      RMS2  \\\n",
            "0 -0.966109 -0.973316 -0.939295 -1.253601   98.632812   764.113883 -0.892981   \n",
            "1 -0.650117 -0.680738 -0.680521 -0.710220  113.769531   815.390316 -1.123034   \n",
            "2 -0.597245 -0.727467 -0.670398 -0.916402   19.042969   793.503828 -0.546691   \n",
            "3 -0.947512 -0.838869 -0.956946 -0.879344  126.220703  1817.091765 -0.869909   \n",
            "4 -0.659996 -0.804357 -0.704610 -1.046086  140.136719   936.011274 -1.472928   \n",
            "\n",
            "         SSI2      MAV2     IEMG2  ...        SSI3      MAV3        IEMG3  \\\n",
            "0  178.454251 -0.958670 -1.221412  ...  252.319595  0.213255   660.665117   \n",
            "1  150.273895 -1.080356 -1.297526  ...  107.358808  0.117995   478.234526   \n",
            "2  261.265206 -0.641587 -0.575766  ...  467.641006  0.276446   934.111800   \n",
            "3  222.571131 -0.866875 -0.602675  ...  591.568116  0.299868  1114.310622   \n",
            "4   97.897332 -1.484718 -1.860272  ...  105.382138  0.110829   472.351795   \n",
            "\n",
            "       PKF3         MNP3    BMI     BF   FFM        OR  DOMS  \n",
            "0 -1.018766  1439.894484  26.45  20.37  64.5  1.080123     1  \n",
            "1  0.095491   724.714243  26.45  20.37  64.5  1.080123     1  \n",
            "2  0.130864  1412.205261  26.45  20.37  64.5  1.080123     1  \n",
            "3  0.042431  1194.683656  26.45  20.37  64.5  1.080123     1  \n",
            "4  2.324003  2157.931252  26.45  20.37  64.5  1.080123     0  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "# Call Dataset\n",
        "test = pd.read_csv(\"Data_training.csv\", delimiter=',')\n",
        "test\n",
        "\n",
        "# Handle missing or non-numeric values\n",
        "test = test.replace(',', '', regex=True)  # Remove commas from numeric values\n",
        "test = test.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
        "\n",
        "# Check for null value\n",
        "test.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "# Remove rows with NaN values\n",
        "test = test.dropna()\n",
        "\n",
        "# Print the resulting testframe\n",
        "test\n",
        "\n",
        "# Scaling\n",
        "scale_columns = ['RMS1', 'SSI1','MAV1', 'IEMG1','RMS2', 'MAV2','IEMG2','PKF2','PKF3','OR']\n",
        "standardScaler = StandardScaler()\n",
        "test[scale_columns] = standardScaler.fit_transform(test[scale_columns])\n",
        "\n",
        "# Display the updated testFrame\n",
        "print(test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y = data['DOMS']\n",
        "X = data.drop(['DOMS'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 5ms/step\n",
            "4/4 [==============================] - 0s 0s/step - loss: 0.0670 - accuracy: 0.9423\n",
            "Test Accuracy: 94.2307710647583 %\n",
            "Test Loss: 6.702828407287598 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        68\n",
            "           1       0.92      0.92      0.92        36\n",
            "\n",
            "    accuracy                           0.94       104\n",
            "   macro avg       0.94      0.94      0.94       104\n",
            "weighted avg       0.94      0.94      0.94       104\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predictions = model.predict(X)\n",
        "\n",
        "# Convert predictions to binary\n",
        "predictions_binary = np.where(predictions >= 0.5, 1, 0)\n",
        "\n",
        "# Evaluate the performance\n",
        "test_loss, test_acc = model.evaluate(X, Y, verbose=1)\n",
        "print(f'Test Accuracy: {test_acc * 100} %')\n",
        "print(f'Test Loss: {test_loss * 100} %')\n",
        "\n",
        "# Confusion Matrix\n",
        "conmat = confusion_matrix(Y, predictions_binary)\n",
        "sns.heatmap(conmat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('true class')\n",
        "plt.ylabel('predicted class')\n",
        "print(classification_report(Y, predictions_binary))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TA_MLPNN Tensor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
